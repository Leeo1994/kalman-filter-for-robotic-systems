#ifndef KalmanFilter_h
#define KalmanFilter_h

class KalmanFilter {
  public: 
    KalmanFilter() : isFirstRun(true) {} //initialize isFirstRun

    float process(float z) {
      
      //constants
      static const float reading_rate = 2.55; // Time step (ms)
      static const float H = 1.0; //measurement map scalar
      static float R = 20; //measurement noise covariance --> the higher the smoother
      static float Q = 0.01; //process noise covariance
      static float P = 1.0; //initial state covariance
      
      //state variable
      static float x = 0.0; //estimated state
      static float x_last = 0.0; //previous state
      static float K = 0.0; //kalman gain
      static float S = 0.0; //innovation covariance
      static float gradient_change_rate = 0.0; //rate of change of state

      //R update variables:
      float z_last_5[5];
      static uint8_t current_idx = 0;

      //store current reading
      z_last_5[current_idx] = z;

      //increment + wrap index
      current_idx = (current_idx + 1) % 5; 

      //first run
      if (isFirstRun) {
        x = z; //initialize with first sensor reading
        isFirstRun = false; //set to false after first reading. 
      }


//--------------BUILDING ERROR COVARIANCES--------------------

//IN SYSTEM:

//assume large steps occur every ___ timestamps. - 

//CHECK WHEN THE LARGE STEPS OCCUR AND BASE YOURSELF OFF OF THAT!

//ASK KORY FOR FULL GRADIENT RUN DATA. 

//ASK CHAT OR COPILOT -
//1. IF I CORRECT MY MODEL TO ANTICIPATE A LARGE INCREASE EVERY ___ TIMESTAMPS AND TO DELTA IT AND EXPECT THE SAME INCREASE EVERY SAME TIMESTAMP - HOW DO I DEFINE ERROR COVARIANCE (Q) IN THIS MODEL?
//2. CAN I INCORORATE BOTH ASSUMPTION OF DELTA INCREASE BASED ON LAST READING AND A LARGE INCREASE EVERY __ ?

/*
Sure! Here's a concise summary of how to use the prediction of large steps to produce the model error covariance:

Identify the Pattern: You know that significant gradient changes (large steps) occur approximately every 1.25 time units.

Adjust Process Noise Covariance ( Q ):

Normal Steps: Use a smaller variance for ( Q ) during regular intervals when no large steps are expected.
Large Steps: Increase the variance in ( Q ) at intervals where large steps are predicted (every 1.25 time units).
Dynamic Adjustment: Implement a function to dynamically adjust ( Q ) based on the current time step. This function will increase ( Q ) at predicted large step intervals to account for higher uncertainty.

Example Pseudo-Code
def get_process_noise_covariance(current_step, step_interval, normal_variance, large_step_variance):
    if current_step % step_interval == 0:
        return large_step_variance
    else:
        return normal_variance

# Prediction step
Q = get_process_noise_covariance(current_step, 1.25, normal_variance, large_step_variance)
x_pred = F * x_prev + B * u
P_pred = F * P_prev * F.T + Q

# Update step
y = z - H * x_pred
S = H * P_pred * H.T + R
K = P_pred * H.T * np.linalg.inv(S)
x_new = x_pred + K * y
P_new = (I - K * H) * P_pred
By dynamically adjusting ( Q ) based on the predicted intervals of large steps, your Kalman filter will better account for the model's uncertainties and improve its accuracy.
*/

//IN READING:

if (current_idx == 0){
float mean = 0;
float var = 0;

  
//calc mean:
for (current_idx = 0; current_idx < 5; current_idx++){
mean += z_last_5[current_idx];
}
mean /= 5.0; //divide accumulated mean by 5 to get avg mean

//calc variance:
for (current_idx = 0; current_idx < 5; current_idx++){
var += (z_last_5[current_idx] - mean) * (z_last_5[current_idx] - mean);
}

var /= 5.0; //divide accumulated variance by 5 to get avg variance

R += var;
}
 
//--------------MODEL-BASED-PREDICTION--------------------

      //predict gradient change rate
      gradient_change_rate = (x - x_last) / reading_rate;

      //predict next state (gradient value)
      float x_predicted = x_last + (gradient_change_rate * reading_rate);
      
      //update process error covariance
      P = P + Q;

//------------MEASUREMENT-BASED-CORRECTION-----------------      

      //calculate innovation covariance
      S = P + R;
      
      //calculate Kalman gain
      K = P / S;

      //correct state estimate
      x = x_predicted + K * (z - H * x_predicted);

      //update measurement error covariance
      P = P * (1 - K * H);

      //store current state for next iteration
      x_last = x;

      //return updated state
      return x;
    }
    
private:
    bool isFirstRun; 
};

#endif
